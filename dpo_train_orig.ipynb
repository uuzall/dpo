{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: Loading binary x:\\python_environments\\AI_310\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\python_environments\\AI_310\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "x:\\python_environments\\AI_310\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('module'), WindowsPath('/matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "x:\\python_environments\\AI_310\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "x:\\python_environments\\AI_310\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n",
      "x:\\python_environments\\AI_310\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F \n",
    "import torch \n",
    "import transformers.optimization as optim \n",
    "# import torch.optim as optim \n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange, tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from datasets import load_dataset \n",
    "from accelerate import Accelerator, DeepSpeedPlugin, accelerator\n",
    "import pickle as pkl \n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, PeftModel, PeftConfig, PeftModelForCausalLM, get_peft_config\n",
    "import pandas as pd\n",
    "import wandb \n",
    "import numpy as np \n",
    "import transformers \n",
    "import re \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda': \n",
    "  print(torch.cuda.get_device_name()) \n",
    "else:\n",
    "  print(device) \n",
    "\n",
    "block_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f\"X:/hf_models/pythia-1b-deduped-v0\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(f\"models/sft_pythia/sft_best_pythia_1b\", torch_dtype=torch.float16, device_map='auto', use_cache=False, pad_token_id=tokenizer.eos_token_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(f\"models/sft_pythia/sft_best_pythia_1b\", torch_dtype=torch.float16, device_map='auto', use_cache=False, pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Asus/.cache/huggingface/datasets/Anthropic___json/Anthropic--hh-rlhf-046a49968e35a6f2/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c001e45d364946b5ea62965a71bf0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Asus/.cache/huggingface/datasets/Anthropic___json/Anthropic--hh-rlhf-bb7971723b14c46c/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb6cc00d5a2421cbaf8f0c5aac9ba6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42537/42537 [00:01<00:00, 32548.41it/s]\n",
      "100%|██████████| 2312/2312 [00:00<00:00, 33503.31it/s]\n",
      "100%|██████████| 43835/43835 [00:01<00:00, 33964.09it/s]\n",
      "100%|██████████| 2354/2354 [00:00<00:00, 34361.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: 34109; Test Data: 1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_1 = load_dataset(\"Anthropic/hh-rlhf\", data_dir='harmless-base')\n",
    "dataset_2 = load_dataset(\"Anthropic/hh-rlhf\", data_dir='helpful-base')\n",
    "\n",
    "x_train, y_train = list(), list() \n",
    "x_test, y_test = list(), list() \n",
    "\n",
    "for dataset in [dataset_1, dataset_2]: \n",
    "\tfor i in tqdm(dataset['train']): \n",
    "\t\tif len(i['chosen']) < block_size and len(i['rejected']) < block_size: \n",
    "\t\t\tchosen = re.sub(r'\\n\\nHuman:', r'<|endoftext|>\\n\\nHuman:', i['chosen']) + '<|endoftext|>'\n",
    "\t\t\trejected = re.sub(r'\\n\\nHuman:', r'<|endoftext|>\\n\\nHuman:', i['rejected']) + '<|endoftext|>'\n",
    "\t\t\tx_train.append((chosen, rejected)) \n",
    "\n",
    "\tfor i in tqdm(dataset['test']): \n",
    "\t\tif len(i['chosen']) < block_size and len(i['rejected']) < block_size: \n",
    "\t\t\tchosen = re.sub(r'\\n\\nHuman:', r'<|endoftext|>\\n\\nHuman:', i['chosen']) + '<|endoftext|>'\n",
    "\t\t\trejected = re.sub(r'\\n\\nHuman:', r'<|endoftext|>\\n\\nHuman:', i['rejected']) + '<|endoftext|>'\n",
    "\t\t\tx_test.append((chosen, rejected)) \n",
    "\n",
    "print(f'Train Data: {len(x_train)}; Test Data: {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33muuzall\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb678f0ed685426ab7665ae1bd7aa9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Asus\\OneDrive\\Programming\\rlhf\\wandb\\run-20230720_214148-34dqx4qe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uuzall/DPO%20Model/runs/34dqx4qe' target=\"_blank\">dauntless-frog-9</a></strong> to <a href='https://wandb.ai/uuzall/DPO%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uuzall/DPO%20Model' target=\"_blank\">https://wandb.ai/uuzall/DPO%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uuzall/DPO%20Model/runs/34dqx4qe' target=\"_blank\">https://wandb.ai/uuzall/DPO%20Model/runs/34dqx4qe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_name = ''\n",
    "\n",
    "wandb.init(\n",
    "    project='DPO Model', \n",
    "    entity='uuzall', \n",
    "    sync_tensorboard=True, \n",
    "    name=project_name, \n",
    "    monitor_gym=True, \n",
    "    save_code=True,\n",
    ")\n",
    "\n",
    "writer = torch.utils.tensorboard.SummaryWriter(f'runs/{project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen, rejected, prompt + chosen, prompt + rejected \n",
    "chosen, rejected, = list(), list()\n",
    "test_chosen, test_rejected = list(), list() \n",
    "\n",
    "for c, r in x_train: \n",
    "  cutoff = c.rfind('\\n\\nAssistant: ') + len('\\n\\nAssistant: ')\n",
    "  chosen.append(c[cutoff:])\n",
    "  cutoff = r.rfind('\\n\\nAssistant: ') + len('\\n\\nAssistant: ')\n",
    "  rejected.append(r[cutoff:])\n",
    "\n",
    "for c, r in x_test: \n",
    "  cutoff = c.rfind('\\n\\nAssistant: ') + len('\\n\\nAssistant: ')\n",
    "  test_chosen.append(c[cutoff:])\n",
    "  cutoff = r.rfind('\\n\\nAssistant: ') + len('\\n\\nAssistant: ')\n",
    "  test_rejected.append(r[cutoff:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_proba(concat_inputs, concat_loss_masks, out): \n",
    "\tlabels = concat_inputs.input_ids[:, 1:].clone() \n",
    "\tlogits = out.logits[:, :-1, :]\n",
    "\tloss_mask = concat_loss_masks.attention_mask[:, :-1].clone().to(device)\n",
    "\tper_token_logp = torch.gather(logits.log_softmax(-1), dim=2, index=labels.unsqueeze(-1)).squeeze(-1)\n",
    "\tloss = (loss_mask * per_token_logp).sum(-1)\n",
    "\treturn loss\n",
    "\n",
    "def dpo_loss(policy_chosen_logps, policy_rejected_logps, reference_chosen_logps, reference_rejected_logps, beta=0.1): \n",
    "\tpi_logratios = policy_chosen_logps - policy_rejected_logps\n",
    "\tref_logratios = reference_chosen_logps - reference_rejected_logps\n",
    "\n",
    "\tlogits = pi_logratios - ref_logratios\n",
    "\n",
    "\tlosses = -F.logsigmoid(beta * logits) \n",
    "\tchosen_rewards = beta * (policy_chosen_logps - reference_chosen_logps).detach()\n",
    "\trejected_rewards = beta * (policy_rejected_logps - reference_rejected_logps).detach()\n",
    "\n",
    "\treturn losses, chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, scale_bs = 64, 8\n",
    "steps = bs // scale_bs \n",
    "train_dl = DataLoader(list(zip(x_train, chosen, rejected)), batch_size=scale_bs, shuffle=True, pin_memory=True)\n",
    "test_dl = DataLoader(list(zip(x_test, test_chosen, test_rejected)) , batch_size=scale_bs, shuffle=False, pin_memory=True)\n",
    "\n",
    "optimizer = optim.Adafactor(model.parameters(), scale_parameter=False, relative_step=False, warmup_init=False, lr=5e-8)\n",
    "scheduler = transformers.get_constant_schedule_with_warmup(optimizer, num_warmup_steps=150)\n",
    "accelerator = Accelerator(gradient_accumulation_steps=steps)\n",
    "model, optimizer, train_dl, test_dl, scheduler = accelerator.prepare(model, optimizer, train_dl, test_dl, scheduler) \n",
    "test_loss, best_test_loss = 0, 100\n",
    "n_epochs = 4\n",
    "global_step = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4264 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 1/4: 100%|██████████| 4264/4264 [1:07:53<00:00,  1.05it/s, best_test_loss=0.693, loss=0.692, test_loss=0.693]  \n",
      "Epochs: 2/4: 100%|██████████| 4264/4264 [1:07:24<00:00,  1.05it/s, best_test_loss=0.693, loss=0.693, test_loss=0.693]  \n",
      "Epochs: 3/4: 100%|██████████| 4264/4264 [1:07:20<00:00,  1.06it/s, best_test_loss=0.692, loss=0.692, test_loss=0.692]  \n",
      "Epochs: 4/4:  26%|██▋       | 1120/4264 [17:54<50:15,  1.04it/s, best_test_loss=0.692, loss=0.687, test_loss=0.692]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m concat_loss_masks \u001b[39m=\u001b[39m tokenizer((chosen \u001b[39m+\u001b[39m rejected), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m, max_length\u001b[39m=\u001b[39mconcat_inputs\u001b[39m.\u001b[39minput_ids\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     42\u001b[0m out \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconcat_inputs\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m---> 43\u001b[0m ref_out \u001b[39m=\u001b[39m ref_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconcat_inputs\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     44\u001b[0m log_proba \u001b[39m=\u001b[39m get_log_proba(concat_inputs, concat_loss_masks, out)\n\u001b[0;32m     45\u001b[0m ref_log_proba \u001b[39m=\u001b[39m get_log_proba(concat_inputs, concat_loss_masks, ref_out)\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:766\u001b[0m, in \u001b[0;36mGPTNeoXForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39mpast_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m    Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[39m>>> prediction_logits = outputs.logits\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[39m```\"\"\"\u001b[39;00m\n\u001b[0;32m    764\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 766\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgpt_neox(\n\u001b[0;32m    767\u001b[0m     input_ids,\n\u001b[0;32m    768\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    769\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    770\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    771\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    772\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    773\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    774\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    775\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    776\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    777\u001b[0m )\n\u001b[0;32m    779\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    780\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_out(hidden_states)\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:657\u001b[0m, in \u001b[0;36mGPTNeoXModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    649\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    650\u001b[0m         create_custom_forward(layer),\n\u001b[0;32m    651\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         head_mask[i],\n\u001b[0;32m    655\u001b[0m     )\n\u001b[0;32m    656\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 657\u001b[0m     outputs \u001b[39m=\u001b[39m layer(\n\u001b[0;32m    658\u001b[0m         hidden_states,\n\u001b[0;32m    659\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    660\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    661\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    662\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    663\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    664\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    665\u001b[0m     )\n\u001b[0;32m    666\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    667\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:420\u001b[0m, in \u001b[0;36mGPTNeoXLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, head_mask, use_cache, layer_past, output_attentions)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    411\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    412\u001b[0m     hidden_states: Optional[torch\u001b[39m.\u001b[39mFloatTensor],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    419\u001b[0m ):\n\u001b[1;32m--> 420\u001b[0m     attention_layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    421\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_layernorm(hidden_states),\n\u001b[0;32m    422\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    423\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    424\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    425\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    426\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    427\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    428\u001b[0m     )\n\u001b[0;32m    429\u001b[0m     attn_output \u001b[39m=\u001b[39m attention_layer_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: attn_output, present, (attn_weights)\u001b[39;00m\n\u001b[0;32m    430\u001b[0m     attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_attention_dropout(attn_output)\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:185\u001b[0m, in \u001b[0;36mGPTNeoXAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, head_mask, layer_past, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m has_layer_past:\n\u001b[0;32m    184\u001b[0m     seq_len \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m layer_past[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m--> 185\u001b[0m cos, sin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrotary_emb(value, seq_len\u001b[39m=\u001b[39;49mseq_len)\n\u001b[0;32m    186\u001b[0m query, key \u001b[39m=\u001b[39m apply_rotary_pos_emb(query_rot, key_rot, cos, sin, position_ids)\n\u001b[0;32m    187\u001b[0m query \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((query, query_pass), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mx:\\python_environments\\AI_310\\lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:320\u001b[0m, in \u001b[0;36mGPTNeoXRotaryEmbedding.forward\u001b[1;34m(self, x, seq_len)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mif\u001b[39;00m seq_len \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_len_cached:\n\u001b[0;32m    319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_cos_sin_cache(seq_len\u001b[39m=\u001b[39mseq_len, device\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 320\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcos_cached[:seq_len, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msin_cached[:seq_len, \u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m]\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs): \n",
    "\tmodel.train()\n",
    "\tref_model.eval()\n",
    "\tfor idx, ((p_chosen, p_rejected), chosen, rejected) in (loop := tqdm(enumerate(train_dl), total=len(train_dl))): \n",
    "\t\tconcat_inputs = tokenizer((p_chosen + p_rejected), return_tensors='pt', max_length=block_size, padding='longest', truncation=True)\n",
    "\t\tconcat_loss_masks = tokenizer((chosen + rejected), return_tensors='pt', max_length=concat_inputs.input_ids.size(1), padding='max_length', truncation=True)\n",
    "\t\tout = model(**concat_inputs.to(device))\n",
    "\t\twith torch.no_grad(): \n",
    "\t\t\tref_out = ref_model(**concat_inputs.to(device))\n",
    "\t\tlog_proba = get_log_proba(concat_inputs, concat_loss_masks, out)\n",
    "\t\tref_log_proba = get_log_proba(concat_inputs, concat_loss_masks, ref_out)\n",
    "\n",
    "\t\tpolicy_chosen_logps = log_proba[:len(p_chosen)]\n",
    "\t\tpolicy_rejected_logps = log_proba[len(p_chosen):]\n",
    "\t\treference_chosen_logps = ref_log_proba[:len(p_chosen)]\n",
    "\t\treference_rejected_logps = ref_log_proba[len(p_chosen):]\n",
    "\n",
    "\t\tloss, chosen_rewards, rejected_rewards = dpo_loss(policy_chosen_logps, policy_rejected_logps, reference_chosen_logps, reference_rejected_logps)\n",
    "\t\tloss = loss.mean() / steps \n",
    "\n",
    "\t\taccelerator.backward(loss) \n",
    "\n",
    "\t\tif idx % steps == 0: \n",
    "\t\t\toptimizer.step() \n",
    "\t\t\tmodel.zero_grad() \n",
    "\t\t\tscheduler.step()\n",
    "\t\tloop.set_description(f'Epochs: {epoch+1}/{n_epochs}')\n",
    "\t\tloop.set_postfix(loss=loss.item()*steps, test_loss=test_loss, best_test_loss=best_test_loss)\n",
    "\n",
    "\t\twriter.add_scalar('charts/learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "\t\twriter.add_scalar('losses/train_loss', loss.item()*steps, global_step)\n",
    "\t\twriter.add_scalar('rewards/chosen_rewards', chosen_rewards.mean().item(), global_step)\n",
    "\t\twriter.add_scalar('rewards/rejected_rewards', rejected_rewards.mean().item(), global_step)\n",
    "\t\t\n",
    "\t\tif idx % (scale_bs*10) == 0: \n",
    "\t\t\tmodel.eval()\n",
    "\t\t\ttest_loss, c_r, r_r = 0, 0, 0 \n",
    "\t\t\twith torch.no_grad(): \n",
    "\t\t\t\tfor (p_chosen, p_rejected), chosen, rejected in test_dl: \n",
    "\t\t\t\t\tconcat_inputs = tokenizer((p_chosen + p_rejected), return_tensors='pt', max_length=block_size, padding='longest', truncation=True)\n",
    "\t\t\t\t\tconcat_loss_masks = tokenizer((chosen + rejected), return_tensors='pt', max_length=concat_inputs.input_ids.size(1), padding='max_length', truncation=True)\n",
    "\t\t\t\t\tout = model(**concat_inputs.to(device))\n",
    "\t\t\t\t\tref_out = ref_model(**concat_inputs.to(device))\n",
    "\t\t\t\t\tlog_proba = get_log_proba(concat_inputs, concat_loss_masks, out)\n",
    "\t\t\t\t\tref_log_proba = get_log_proba(concat_inputs, concat_loss_masks, ref_out)\n",
    "\n",
    "\t\t\t\t\tpolicy_chosen_logps = log_proba[:len(p_chosen)]\n",
    "\t\t\t\t\tpolicy_rejected_logps = log_proba[len(p_chosen):]\n",
    "\t\t\t\t\treference_chosen_logps = ref_log_proba[:len(p_chosen)]\n",
    "\t\t\t\t\treference_rejected_logps = ref_log_proba[len(p_chosen):]\n",
    "\n",
    "\t\t\t\t\tloss, chosen_rewards, rejected_rewards = dpo_loss(policy_chosen_logps, policy_rejected_logps, reference_chosen_logps, reference_rejected_logps)\n",
    "\t\t\t\t\ttest_loss += loss.sum().item()\n",
    "\t\t\t\t\tc_r += chosen_rewards.sum().item() \n",
    "\t\t\t\t\tr_r += rejected_rewards.sum().item() \n",
    "\n",
    "\t\t\t\ttest_loss /= len(x_test) \n",
    "\t\t\t\tc_r /= len(x_test) \n",
    "\t\t\t\tr_r /= len(x_test)\n",
    "\t\t\tif np.abs(test_loss) < np.abs(best_test_loss): \n",
    "\t\t\t\tbest_test_loss = test_loss \n",
    "\t\t\t\taccelerator.wait_for_everyone()\n",
    "\t\t\t\tunwrapped_model = accelerator.unwrap_model(model)\n",
    "\t\t\t\tunwrapped_model.save_pretrained(f'models/dpo/pythia_1b_best_performing_5e8', save_function=accelerator.save, state_dict=accelerator.get_state_dict(model))\n",
    "\t\t\tmodel.train()\n",
    "\t\t\twriter.add_scalar('losses/test_loss', test_loss, global_step)\n",
    "\t\t\twriter.add_scalar('rewards/test_chosen_rewards', c_r, global_step)\n",
    "\t\t\twriter.add_scalar('rewards/test_rejected_rewards', r_r, global_step)\n",
    "\n",
    "\t\tglobal_step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
